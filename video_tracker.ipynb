{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c4e7ca",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d300b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import numpy as np\n",
    "import imutils\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0a0a4",
   "metadata": {},
   "source": [
    "# creating a class to track the details of the centriod along with their boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e24accf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50, maxDistance=50):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.track_time = OrderedDict()\n",
    "        self.objectclass = OrderedDict()\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.bbox = OrderedDict()  # CHANGE\n",
    "        self.fileName = ''\n",
    "        self.final_file_name = ''\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "        # store the maximum distance between centroids to associate\n",
    "        # an object -- if the distance is larger than this maximum\n",
    "        # distance we'll start to mark the object as \"disappeared\"\n",
    "        self.maxDistance = maxDistance\n",
    "\n",
    "    def register(self, centroid, inputRect,classes):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.objectclass[self.nextObjectID] = classes\n",
    "        self.bbox[self.nextObjectID] = inputRect  # CHANGE\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.track_time[self.nextObjectID] = datetime.datetime.now()\n",
    "        self.storeObjectDetails(self.fileName,self.objectclass[self.nextObjectID],self.nextObjectID,self.track_time[self.nextObjectID],' ')\n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        #print(self.objectclass[objectID],self.objects[objectID],self.track_time[objectID],datetime.datetime.now())\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.bbox[objectID]  # CHANGE\n",
    "        del self.objectclass[objectID]\n",
    "        del self.track_time[objectID]\n",
    "    \n",
    "    def storeObjectDetails(self,file,name,obectID,startTime,endTime):\n",
    "        \n",
    "        if endTime != ' ':\n",
    "            duration = str(endTime - startTime)\n",
    "        else: \n",
    "            duration =' '\n",
    "            \n",
    "        details = ['Object','Id','Display Name','Start Time','End Time','Duration']\n",
    "        rows = [[name,obectID,'{} {}'.format(name,obectID),startTime,endTime,duration]]\n",
    "        file_name = '{}_tracked_details.csv'.format(file)\n",
    "        path = 'Output/{}'.format(file_name)\n",
    "        self.final_file_name = file_name\n",
    "        \n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'a') as w:\n",
    "                write = csv.writer(w) \n",
    "                write.writerows(rows)\n",
    "        else:\n",
    "            with open(path, \"w\") as f:\n",
    "                write = csv.writer(f) \n",
    "                write.writerow(details) \n",
    "                write.writerows(rows)\n",
    "\n",
    "    def update(self, rects, classes, file_name):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        self.fileName = file_name\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.storeObjectDetails(self.fileName,self.objectclass[objectID],objectID,self.track_time[objectID],datetime.datetime.now())\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            # return self.objects\n",
    "            return self.bbox, self.objectclass \n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        inputRects = []\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            inputRects.append(rects[i])  # CHANGE\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i], inputRects[i],classes[i])  # CHANGE\n",
    "\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # if the distance between centroids is greater than\n",
    "                # the maximum distance, do not associate the two\n",
    "                # centroids to the same object\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.bbox[objectID] = inputRects[col]  # CHANGE\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.storeObjectDetails(self.fileName,self.objectclass[objectID],objectID,self.track_time[objectID],datetime.datetime.now())\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col], inputRects[col],classes[col])\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        # return self.objects\n",
    "        return self.bbox, self.objectclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ea0a2",
   "metadata": {},
   "source": [
    "# creating a function to identify all the boxes when multiple object boxes will be detect at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32fe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    try:\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "\n",
    "        if boxes.dtype.kind == \"i\":\n",
    "            boxes = boxes.astype(\"float\")\n",
    "\n",
    "        pick = []\n",
    "\n",
    "        x1 = boxes[:, 0]\n",
    "        y1 = boxes[:, 1]\n",
    "        x2 = boxes[:, 2]\n",
    "        y2 = boxes[:, 3]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        while len(idxs) > 0:\n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "\n",
    "            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "            w = np.maximum(0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "            overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "            idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                                   np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "        return boxes[pick].astype(\"int\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred in non_max_suppression : {}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad995241",
   "metadata": {},
   "source": [
    "# defining a function to track the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "226528ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_video(tracker,video,store):\n",
    "    \n",
    "    #if user has provided the video path\n",
    "    if video != 'no':\n",
    "        \n",
    "        print('')\n",
    "        \n",
    "        #reading video from the given path\n",
    "        cap = cv2.VideoCapture(video)\n",
    "\n",
    "        #extracting the video name from the path\n",
    "        file_name = Path(video).stem\n",
    "        \n",
    "        video_name = '{}_tracked_video.avi'.format(file_name)\n",
    "        \n",
    "        #if user wants to store tracked video\n",
    "        if store.lower() == 'y':\n",
    "            \n",
    "            #extracting the height and width of the frame of the video\n",
    "            frame_width = int(cap.get(3))\n",
    "            frame_height = int(cap.get(4))\n",
    "            \n",
    "            #creating object to store the video\n",
    "            out = cv2.VideoWriter('Output/{}'.format(video_name),cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "        while(True):\n",
    "\n",
    "            # reading frame from the video\n",
    "            ret, frame = cap.read()    \n",
    "            \n",
    "            if ret == False:\n",
    "                break\n",
    "            \n",
    "            # passing the read frames to the YOLOV5s model\n",
    "            results = model(frame)\n",
    "\n",
    "            # finding the x1,y1,x2,y2 coordinates and labels of the bounding boxes of the detected objects in the video from the result object\n",
    "            cords = results.xyxy[0].numpy()\n",
    "\n",
    "            boxes = []\n",
    "            classes = []\n",
    "            # reading individual box data(box coordinates and classes)\n",
    "            for c in cords:\n",
    "                box = c[0:4]\n",
    "                #print(box)\n",
    "                boxes.append(box)\n",
    "                classes.append(results.names[int(c[5])])\n",
    "            \n",
    "            boxes = np.array(boxes)\n",
    "            boxes = boxes.astype(\"int\")\n",
    "            boxes = non_max_suppression_fast(boxes, 0.3)\n",
    "            objects, classes = tracker.update(boxes,classes,file_name)\n",
    "\n",
    "            #reading objectIds and their corresponding boxes and classes \n",
    "            for (objectId, bbox) in objects.items():\n",
    "                \n",
    "                x1, y1, x2, y2 = bbox\n",
    "                x1 = int(x1)\n",
    "                y1 = int(y1)\n",
    "                x2 = int(x2)\n",
    "                y2 = int(y2)\n",
    "                \n",
    "                #creating boxes arround the objects\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                text = \"{} {}\".format(classes[objectId],objectId)\n",
    "                #putting text for the boxes in the video\n",
    "                cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "                \n",
    "            if store.lower() == 'y':\n",
    "                # here writing the video using the out object that we have created above\n",
    "                out.write(frame)\n",
    "            cv2.imshow('video',frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return video_name, tracker.final_file_name\n",
    "    \n",
    "    #if user wants for live video\n",
    "    elif video == 'no':\n",
    "        \n",
    "        #reading live video\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        #giving name to the video\n",
    "        file_name = 'live'\n",
    "        \n",
    "        video_name = '{}_tracked_video.avi'.format(file_name)\n",
    "        \n",
    "        \n",
    "        #if user wants to store tracked video\n",
    "        if store.lower() == 'y':\n",
    "            \n",
    "            #extracting the height and width of the frame of the video\n",
    "            frame_width = int(cap.get(3))\n",
    "            frame_height = int(cap.get(4))\n",
    "            \n",
    "            #creating object to store the video\n",
    "            out = cv2.VideoWriter('Output/{}'.format(video_name),cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "        while(True):\n",
    "\n",
    "            # reading frame from the video\n",
    "            ret, frame = cap.read()    \n",
    "            \n",
    "            if ret == False:\n",
    "                break\n",
    "                \n",
    "            # passing the read frames to the YOLOV5s model\n",
    "            results = model(frame)\n",
    "\n",
    "            # finding the x1,y1,x2,y2 coordinates and labels of the bounding boxes of the detected objects in the video from the result object\n",
    "            cords = results.xyxy[0].numpy()\n",
    "\n",
    "            boxes = []\n",
    "            classes = []\n",
    "            # reading individual box data(box coordinates and classes)\n",
    "            for c in cords:\n",
    "                box = c[0:4]\n",
    "                #print(box)\n",
    "                boxes.append(box)\n",
    "                classes.append(results.names[int(c[5])])\n",
    "            \n",
    "            boxes = np.array(boxes)\n",
    "            boxes = boxes.astype(\"int\")\n",
    "            boxes = non_max_suppression_fast(boxes, 0.3)\n",
    "            objects, classes = tracker.update(boxes,classes,file_name)\n",
    "\n",
    "            #reading objectIds and their corresponding boxes and classes \n",
    "            for (objectId, bbox) in objects.items():\n",
    "                \n",
    "                x1, y1, x2, y2 = bbox\n",
    "                x1 = int(x1)\n",
    "                y1 = int(y1)\n",
    "                x2 = int(x2)\n",
    "                y2 = int(y2)\n",
    "                \n",
    "                #creating boxes arround the objects\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                text = \"{} {}\".format(classes[objectId],objectId)\n",
    "                #putting text for the boxes in the video\n",
    "                cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "                \n",
    "            if store.lower() == 'y':\n",
    "                # here writing the video using the out object that we have created above\n",
    "                out.write(frame)\n",
    "            cv2.imshow('Live video',frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return video_name, tracker.final_file_name\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4fa3deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\MSI 1/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-8-31 torch 1.9.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one option LIVE VIDEO TRACKING / NORMAL VIDEO TRACKING for LIVE press (L/l) and for NORMAL press (N/n)l\n",
      "Do you want to store tracked video (Y/N)y\n",
      "Tracked video has been saved with live_tracked_video.avi name and CSV tracked file has been saved with name live_tracked_details.csv\n"
     ]
    }
   ],
   "source": [
    "#creating object of \"CentroidTracker\" class\n",
    "tracker = CentroidTracker(maxDisappeared=0, maxDistance=90)\n",
    "\n",
    "# creating model after loading yolov5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "choice = input('Select one option LIVE VIDEO TRACKING / NORMAL VIDEO TRACKING for LIVE press (L/l) and for NORMAL press (N/n)')\n",
    "choice = choice.lower()\n",
    "\n",
    "if os.path.isdir('Output') == False:\n",
    "    os.mkdir('Output')\n",
    "\n",
    "if choice == 'n':\n",
    "    \n",
    "    video = input('Please enter the video path')\n",
    "    store = input('Do you want to store tracked video (Y/N)')\n",
    "    \n",
    "    if store.lower() == 'n' or store.lower() == 'y':\n",
    "        video_name,file_name = track_video(tracker,video,store)\n",
    "        print('Tracked video has been saved with {} name and CSV tracked file has been saved with name {}'.format(video_name,file_name))\n",
    "    else:\n",
    "        print('Please choose correct option for store (Y/N)')\n",
    "        \n",
    "elif choice == 'l':\n",
    "    \n",
    "    video ='no'\n",
    "    store = input('Do you want to store tracked video (Y/N)')\n",
    "    \n",
    "    if store.lower() == 'n' or store.lower() == 'y':\n",
    "        video_name,file_name = track_video(tracker,video,store)\n",
    "        print('Tracked video has been saved with {} name and CSV tracked file has been saved with name {}'.format(video_name,file_name))\n",
    "    else:\n",
    "        print('Please choose correct option for store (Y/N)')\n",
    "        \n",
    "else:\n",
    "    print('Please select the correct option')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5be38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "352fd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dt.timestamp()-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46392158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-04 02:53:49.294698\n"
     ]
    }
   ],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d96c9835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-04 02:53:39.294698\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.fromtimestamp(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "20687e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03891004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
